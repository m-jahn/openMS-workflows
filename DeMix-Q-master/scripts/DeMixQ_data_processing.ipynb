{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "# 2016.1.6 revised\n",
    "from __future__ import division\n",
    "import pandas, numpy, csv, re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "\n",
    "from cStringIO import StringIO\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "get_ipython().magic(u'matplotlib inline')\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 8.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "consensus_txt = r\"../example/016-TextExporter-out/JD_06232014_sample1-A.csv\"\n",
    "eic_txt = r\"../example/020-EICExtractor-out/JD_06232014_sample1-A.csv\"\n",
    "\n",
    "num_samples = 4\n",
    "num_replica = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_consensus(fn):\n",
    "    '''\n",
    "    Read text table from consensusXML exported by OpenMS TextExporter\n",
    "    '''\n",
    "    cons_header = []\n",
    "    pept_header = []\n",
    "    runs_name = []\n",
    "\n",
    "    # fetch the headers for consensus features, unassigned peptides and experiments' names. \n",
    "    for row in csv.reader(open(fn), delimiter='\\t'):\n",
    "        if row[0] == '#CONSENSUS':\n",
    "            cons_header = row\n",
    "        elif row[0] == '#UNASSIGNEDPEPTIDE':\n",
    "            pept_header = row\n",
    "        elif row[0] == 'MAP':\n",
    "            runs_name.append(row[2])\n",
    "\n",
    "    # read consensus features\n",
    "    s = StringIO()\n",
    "    with open(fn) as fh:\n",
    "        for line in fh:\n",
    "            if line.startswith(\"CONSENSUS\"):\n",
    "                s.write(line)\n",
    "    s.seek(0)\n",
    "    cons = pandas.read_csv(s, sep='\\t', header=None, names=cons_header)\n",
    "    co_peps = []\n",
    "    with open(fn) as fh:\n",
    "        for line in fh:\n",
    "            if line.startswith(\"CONSENSUS\"):\n",
    "                co_peps.append('')\n",
    "            elif line.startswith('PEPTIDE') and co_peps[-1] == '':\n",
    "                # choose the first recorded peptide sequence as consensus sequence\n",
    "                co_peps[-1] = line.split(\"\\t\")[5]\n",
    "    cons['peptide_0'] = co_peps\n",
    "    \n",
    "    # read uassigned peptides as consensus features\n",
    "    s = StringIO()\n",
    "    with open(fn) as fh:\n",
    "        for line in fh:\n",
    "            if line.startswith(\"UNASSIGNEDPEPTIDE\"):\n",
    "                s.write(line)\n",
    "    s.seek(0)\n",
    "    ua_peps = pandas.read_csv(s, sep='\\t', header=None, names=pept_header)\n",
    "    ua_peps = ua_peps.groupby(['sequence', 'charge']).mean()\n",
    "    \n",
    "    return cons, ua_peps, runs_name\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def read_eic(fn):\n",
    "    '''\n",
    "    Read the detailed output file from EIC extraction in OpenMS.\n",
    "    Two isotopic peaks (M and M+1) are extracted for each consensus feature and unassigned peptide\n",
    "    Calculate geometric average of intensities from the two isotopic peaks, as well as diviations of RT and mass.\n",
    "    '''\n",
    "    \n",
    "    with open(fn) as fh:\n",
    "        eic_str = [StringIO() for _ in range(4)]\n",
    "        sample_header = [i for i in fh.next().rstrip().split(',') if i] # sample row\n",
    "        fh.next() # empty row\n",
    "        cols = fh.next().rstrip().split(',') # quantity headers\n",
    "        for ix in range(2, len(cols)):\n",
    "            i = int((ix-2)/5)\n",
    "            cols[ix] = '_'.join([sample_header[i], cols[ix]]) # rename columns according to sample names\n",
    "        \n",
    "        ix = 0\n",
    "        for line in fh:\n",
    "            eic_str[ix % 4].write(line)\n",
    "            ix += 1\n",
    "\n",
    "        [sio.seek(0) for sio in eic_str]\n",
    "\n",
    "    # obtain quantities from M and M+1 of target and decoy features, separately.\n",
    "    eic = pandas.read_csv(eic_str[0], header=None, names=cols) # Monoisotopic    \n",
    "    eic_iso = pandas.read_csv(eic_str[1], header=None, names=cols) # 13C isotope\n",
    "    eic_decoy0 = pandas.read_csv(eic_str[2], header=None, names=cols)\n",
    "    eic_decoy1 = pandas.read_csv(eic_str[3], header=None, names=cols)\n",
    "    \n",
    "    for samp in sample_header:\n",
    "        int_ix = samp + '_intensity'\n",
    "        rt_ix = samp + '_dRT'\n",
    "        ppm_ix = samp + '_dppm'\n",
    "\n",
    "        # values of target features\n",
    "        eic[samp + '_int_1'] = (eic[int_ix] * eic_iso[int_ix]) ** 0.5\n",
    "        eic[samp + '_dRT_1'] = eic[rt_ix] - eic_iso[rt_ix]\n",
    "        eic[samp + '_ppm_1'] = eic[ppm_ix] - eic_iso[ppm_ix]\n",
    "\n",
    "        # values of decoy features\n",
    "        eic[samp + '_int_d1'] = (eic_decoy0[int_ix] * eic_decoy1[int_ix]) ** 0.5\n",
    "        eic[samp + '_dRT_d0'] = eic_decoy0[rt_ix] \n",
    "        eic[samp + '_dRT_d1'] = eic_decoy0[rt_ix] - eic_decoy1[rt_ix]\n",
    "        eic[samp + '_ppm_d0'] = eic_decoy0[ppm_ix]\n",
    "        eic[samp + '_ppm_d1'] = eic_decoy0[ppm_ix] - eic_decoy1[ppm_ix]\n",
    "        \n",
    "    return eic\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def median_shift(dat, rcol, scol, knn=15, span=500):\n",
    "    '''\n",
    "    Predict median shift (fold-change) of ion intensity at a given RT, using KNN regression\n",
    "    rcol: column of global medians\n",
    "    scol: columm of extracted intensities of one sample\n",
    "    knn:  number of k nearest neighbors  \n",
    "    span: number of features for median shift calculation. \n",
    "    '''\n",
    "    \n",
    "    d = dat[(dat[scol] > 0) & (dat[rcol] > 0)].sort(columns=['rt_cf'])\n",
    "    \n",
    "    x = d['rt_cf'].values\n",
    "    y = numpy.log2(d[scol] / d[rcol]) # fold-change\n",
    "\n",
    "    X = numpy.array([numpy.mean(x[i:i+span]) for i in range(0, len(x), int(span/10))])\n",
    "    y = numpy.array([numpy.median(y[i:i+span]) for i in range(0, len(x),int(span/10))])\n",
    "    reg = KNeighborsRegressor(n_neighbors=knn)\n",
    "    reg.fit(numpy.matrix(X).T, numpy.matrix(y).T)\n",
    "    \n",
    "    return reg, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eic = read_eic(eic_txt)\n",
    "cons, uapep, ic0 = read_consensus(consensus_txt)\n",
    "\n",
    "# replace Intensity Column names\n",
    "icols = [i for i in cons.columns if i.startswith('intensity_')]\n",
    "cons = cons[icols + ['quality_cf', 'peptide_0', 'charge_cf', 'rt_cf', 'mz_cf']]\n",
    "cons.rename(columns=dict(zip(icols[1:], ic0)), inplace=True)\n",
    "\n",
    "# please pardon me for the confusing variable namings here.\n",
    "# ic1x => feature Intensity Column 1 :XIC (geometric average of M and M+1) \n",
    "ic1x = [i for i in eic.columns if i.endswith('int_1')]\n",
    "\n",
    "# column names of consensus (targets)\n",
    "crt0 = [i for i in eic.columns if i.endswith('dRT')]\n",
    "crt1 = [i for i in eic.columns if i.endswith('dRT_1')]\n",
    "cppm0 = [i for i in eic.columns if i.endswith('ppm')]\n",
    "cppm1 = [i for i in eic.columns if i.endswith('ppm_1')]\n",
    "\n",
    "# column names of decoys\n",
    "dic1x = [i for i in eic.columns if i.endswith('int_d1')]\n",
    "drt0 = [i for i in eic.columns if i.endswith('dRT_d0')]\n",
    "drt1 = [i for i in eic.columns if i.endswith('dRT_d1')]\n",
    "dppm0 = [i for i in eic.columns if i.endswith('ppm_d0')]\n",
    "dppm1 = [i for i in eic.columns if i.endswith('ppm_d1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# combine Feature and XIC into dataframe_X\n",
    "dx = pandas.concat([eic, cons], axis=1)\n",
    "dx['peptide_0'] = [i for i in cons.peptide_0]  + [ i[0] for i in uapep.index.tolist()]\n",
    "dx['charge_cf'] = [i for i in cons.charge_cf]  + [ i[1] for i in uapep.index.tolist()]\n",
    "dx['mz_cf'] = [i for i in cons.mz_cf] + uapep.mz.tolist()\n",
    "dx['rt_cf'] = [i for i in cons.rt_cf] + uapep.rt.tolist()\n",
    "dx = dx[dx.rt_cf > 0]\n",
    "\n",
    "dx['peptide'] = [ re.sub('C\\(Carbamidomethyl\\)', 'C', str(i)) for i in dx.peptide_0]\n",
    "dx['baseseq'] = [ re.sub('\\(.+?\\)', '', str(i)) for i in dx.peptide_0]\n",
    "\n",
    "dx['mods'] = [ sorted(re.findall('\\(.+?\\)', str(i))) for i in dx.peptide ]\n",
    "dx['uniq'] = [ \"%s%d%s\" % (x.baseseq, x.charge_cf, ''.join(x.mods)) for i, x in dx.iterrows()]\n",
    "\n",
    "# cross-run quantifications from feature-based linking.\n",
    "dx['f_overlap'] = [ numpy.count_nonzero(numpy.nan_to_num(i)) for i in dx[ic0].values ]\n",
    "# cross-run quantifications from ion-based linking. \n",
    "dx['e_overlap'] = [ numpy.count_nonzero(i) for i in dx[ic1x].values ]\n",
    "# median intensity in each individual run\n",
    "dx['medianEIC'] = dx[ic1x].median(axis=1)\n",
    "\n",
    "print \"number of features:\\t\", len(dx)\n",
    "print \"number of runs:\\t\", len(ic1x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# XIC extraction rate for consensus features\n",
    "e = numpy.array(dx[dx.intensity_cf.isnull() == False].e_overlap).tolist() \n",
    "print e.count(len(ic1x)) * 100 / len(e), \"% of \", len(e) , \" consensus features are extracted across all runs.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reference set: consensus features with no missing values in both feature linking and XIC extraction\n",
    "refdx = dx[(dx.f_overlap ==len(ic0)) & (dx.e_overlap == len(ic0))]\n",
    "\n",
    "fcol = numpy.concatenate([crt0, crt1, cppm0, cppm1])\n",
    "dcol = numpy.concatenate([drt0, drt1, dppm0, dppm1])\n",
    "\n",
    "# unit-less transformation\n",
    "refz = (refdx[fcol] - refdx[fcol].mean()) / refdx[fcol].std()\n",
    "decoyz = (refdx[dcol] - refdx[fcol].mean().values) / refdx[fcol].std().values\n",
    "testz = (dx[fcol] - refdx[fcol].mean()) / refdx[fcol].std()\n",
    "\n",
    "for i in numpy.array(ic1x).reshape(num_samples, num_replica):\n",
    "    cv = refdx[i].std(axis=1) / refdx[i].mean(axis=1)\n",
    "    cv = numpy.sqrt(cv)\n",
    "    for run_id in i:\n",
    "        refz[run_id + '_cv'] = cv\n",
    "    \n",
    "for i in numpy.array(dic1x).reshape(num_samples, num_replica):    \n",
    "    cv = refdx[i].std(axis=1) / refdx[i].mean(axis=1)\n",
    "    cv = numpy.sqrt(cv)\n",
    "    for run_id in i:\n",
    "        decoyz[run_id + '_cv'] = cv\n",
    "\n",
    "for i in numpy.array(ic1x).reshape(num_samples, num_replica):\n",
    "    cv = dx[i].std(axis=1) / dx[i].mean(axis=1)\n",
    "    cv = numpy.sqrt(cv)\n",
    "    for run_id in i:\n",
    "        testz[run_id + '_cv'] = cv    \n",
    "        \n",
    "ccv = [i for i in refz.columns if i.endswith('cv')]\n",
    "dcv = [i for i in decoyz.columns if i.endswith('cv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print refdx[cppm0].mean()\n",
    "print refdx[cppm0].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fil_cols = zip(ic1x, crt0, crt1, cppm0, cppm1, ccv)\n",
    "fil_cols_decoy = zip(dic1x, drt0, drt1, dppm0, dppm1, dcv)\n",
    "\n",
    "zscores = []\n",
    "for f in fil_cols:\n",
    "    e = refdx[f[0]] > 0\n",
    "    rz = refz[e]\n",
    "    z = [numpy.sum(v*v) for v in rz[list(f[1:])].values]\n",
    "    zscores = zscores + z\n",
    "\n",
    "dzscores = []\n",
    "for f in fil_cols_decoy:\n",
    "    e = refdx[f[0]] > 0\n",
    "    dd = decoyz[e]\n",
    "    z = [numpy.sum(v*v) for v in dd[list(f[1:])].values]\n",
    "    dzscores = dzscores + z\n",
    "\n",
    "\n",
    "bins = numpy.arange(-6.6, 4.5, 0.1)\n",
    "pandas.Series(-numpy.log(zscores)).hist(bins=bins, alpha = 0.5, color ='b', lw=0, label='Target')\n",
    "pandas.Series(-numpy.log(dzscores)).hist(bins=bins, alpha = 0.5, color='r', lw=0, label='Decoy')\n",
    "# pandas.Series(-numpy.log(tzscores)).hist(bins=bins, alpha = 0.3, color='y', lw=0, label='All')\n",
    "plt.legend()\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('# Features')\n",
    "\n",
    "\n",
    "score_list = sorted(zip(zscores + dzscores, [0 for i in zscores] + [1 for i in zscores]), key=lambda x: x[0])\n",
    "score_cutoff = 0\n",
    "hit_count = 0\n",
    "decoy_count = 0\n",
    "\n",
    "# set FDR threshold \n",
    "fdr = 0.05\n",
    "for s in score_list:\n",
    "    hit_count += 1\n",
    "    score_cutoff = -numpy.log(s[0])\n",
    "    if s[1] > 0:\n",
    "        decoy_count += 1\n",
    "    if decoy_count / hit_count >= fdr:\n",
    "        print \"cutoff score:\", score_cutoff\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fil_cols = zip(ic1x, crt0, crt1, cppm0, cppm1, ccv)\n",
    "for f in fil_cols:\n",
    "    score = numpy.array([numpy.sum(v*v) for v in testz[list(f[1:])].values])\n",
    "    score = -numpy.log(score)\n",
    "    print list(score > score_cutoff).count(True) / len(score)\n",
    "    dx[f[0]][list(score <= score_cutoff )] = 0 # XIC filter\n",
    "\n",
    "    \n",
    "dx['medianEIC'] = dx[dx[ic1x] > 0][ic1x].median(axis=1)\n",
    "dx['e_overlap'] = [ numpy.count_nonzero(i) for i in dx[ic1x].values ]\n",
    "\n",
    "\n",
    "print \"Features before filtering:\\t\", len(dx)\n",
    "\n",
    "# quantified at least in one run in each sample\n",
    "ix = numpy.min([numpy.mean(dx[i].values, axis=1) for i in numpy.array(ic1x).reshape(num_samples, num_replica)], axis=0) > 0 \n",
    "\n",
    "# or quantified at least in half of samples\n",
    "ix = dx.e_overlap > 0.5 * num_samples * num_replica\n",
    "\n",
    "\n",
    "# dx: missing value filtered dataframe_X\n",
    "dx = dx[ix]\n",
    "\n",
    "\n",
    "print \"Features after filtering:\\t\", len(dx)\n",
    "print \"Unique peptide sequences:\\t\", len(dx.baseseq.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "icols = zip(ic0, ic1x)\n",
    "for a in icols[:]:\n",
    "    do = dx[pandas.notnull(dx[a[0]])]\n",
    "    do = do[do[a[1]] > 0]\n",
    "    xy = do[list(a)].apply(numpy.log2).values\n",
    "    r2 = pearsonr(xy[:,0], xy[:, 1])[0] ** 2\n",
    "    print a[1], len(xy), r2\n",
    "    \n",
    "    if r2 < 0.5:\n",
    "        # Remove problematic runs with low correlation between feature abundance and XIC intensity.\n",
    "        icols.remove(a)\n",
    "        print a, \" has been removed due to low correlation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# log2 transform of selected intensity colums from the dataframe_X\n",
    "data = dx[ic0 + ic1x].apply(numpy.log2)\n",
    "\n",
    "# impute remaining missing values as the minimum detectable intensity\n",
    "data[data==-numpy.inf] = data[data!=-numpy.inf][ic1x].min().min()\n",
    "\n",
    "# or impute missing values as zero intensity\n",
    "# data[data==-numpy.inf] = 0\n",
    "\n",
    "data['rt'] = dx['rt_cf']\n",
    "data['mass'] = dx['mz_cf'] * dx['charge_cf']\n",
    "data['charge'] = dx['charge_cf']\n",
    "data['peptide'] = dx.peptide\n",
    "data['baseseq'] = dx.baseseq\n",
    "data['uniq'] = dx.uniq \n",
    "\n",
    "for a, b in icols:\n",
    "    dn = data[(data[a].notnull()) & (data[b] > 0)]\n",
    "    mx = numpy.matrix(dn[[a,b,'mass']])\n",
    "    \n",
    "    # KNN regression (k=5 by default) for predicting feature abundance (log2) based on ion intensity and precosor mass\n",
    "    regr = KNeighborsRegressor().fit(mx[:,1:], mx[:,0])\n",
    "    a_ = regr.predict(numpy.matrix(data[[b, 'mass']]))[:,0]  \n",
    "    a_[data[b].values==0] = 0 # keep missing values from extraction\n",
    "    data[a + '_'] = a_\n",
    "\n",
    "ic2 = [a+'_' for a in ic0]\n",
    "tmp = dx[ic0].apply(numpy.log2)\n",
    "tmp.values[numpy.isnan(tmp.values)] = data[ic2].values[numpy.isnan(tmp.values)]\n",
    "data[ic0] = tmp.apply(numpy.exp2) # converting back to linear scale\n",
    "\n",
    "\n",
    "print data[ic0].values.flatten().tolist().count(1) * 1. / data[ic0].values.flatten().__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# quantified vs. identified\n",
    "print len(data[data.peptide != '']) *100./ data[ic0].__len__(), \"% features have been assigned with peptide sequence.\"\n",
    "data[ic0].apply(numpy.log10).median(axis=1).hist(bins=numpy.arange(5,11,0.1), lw=0, alpha=0.9)\n",
    "data[data.peptide != ''][ic0].apply(numpy.log10).median(axis=1).hist(bins=numpy.arange(5,11,0.1), lw=0, alpha=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# median-shift correction\n",
    "data1 = data.copy(deep=True)\n",
    "for a, b in icols:\n",
    "    reg, _, _ = median_shift(dx, 'medianEIC', b, knn=5, span=500)\n",
    "    data1[a] = numpy.log2(data1[a]) - reg.predict(numpy.matrix(data1.rt).T).T[0]\n",
    "\n",
    "# keep identified features    \n",
    "pepdata = data1[data1.peptide != '']\n",
    "\n",
    "# remove duplications\n",
    "pepdata.drop_duplicates(subset=['uniq'], inplace=True)\n",
    "\n",
    "# convert back to linear intensity space\n",
    "pepdata[ic0] = 2 ** pepdata[ic0]\n",
    "\n",
    "# remove modified peptides?\n",
    "# pepdata = pepdata[[len(i) == 0 for i in pepdata.mods]]\n",
    "\n",
    "\n",
    "# report matrix\n",
    "mx = pepdata.groupby(['baseseq'])[ic0].sum()\n",
    "for i in ic0:\n",
    "    mx[i] = mx[i] / mx[i].mean() * mx[ic0].values.flatten().mean()\n",
    "\n",
    "# save peptide-level quantification result to a CSV file\n",
    "mx.to_csv(r'../example/peptide_quant.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot median-shift correction (data vs data1)\n",
    "import random\n",
    "randix = random.sample(data[data.peptide != ''].index, int(len(data)/10))\n",
    "before = data.ix[randix]\n",
    "after = data1.ix[randix]\n",
    "alpha_value = 0.01\n",
    "pylab.rcParams['figure.figsize'] = (15.0, 15.0)\n",
    "f, axs = plt.subplots(12, 12, sharex='col', sharey='row')\n",
    "for i in range(12):\n",
    "    a, b = icols[i]\n",
    "    reg, _, _ = median_shift(dx, 'medianEIC', b, knn=5, span=500)\n",
    "    rtspace = numpy.arange(8000)\n",
    "    \n",
    "    for j in range(12):\n",
    "        if i == j:\n",
    "            # correction curve:\n",
    "            axs[i][j].scatter(rtspace, reg.predict(numpy.matrix(rtspace).T).T[0], marker='.', alpha=0.05, color='r')\n",
    "        elif i > j:\n",
    "            axs[i][j].scatter(before.rt, numpy.log2(before[ic0[i]]) - numpy.log2(before[ic0[j]]), marker='.', alpha=alpha_value)\n",
    "\n",
    "        elif i < j:\n",
    "            axs[i][j].scatter(after.rt, after[ic0[i]] - after[ic0[j]], marker='.', alpha=alpha_value)\n",
    "\n",
    "for a in numpy.array(axs).flatten():\n",
    "    a.set_xlim([0,8000])\n",
    "    a.set_xticks([])\n",
    "    a.set_ylim([-2,2])\n",
    "    a.set_yticks([-2,0,2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
